# DiffGAN: Differential Testing of DNNs using GAN-Based Test Generation

## Overview
This repository contains the replication package for the **DiffGAN** project. DiffGAN is a novel, black-box test generation approach designed to identify behavioral discrepancies between Deep Neural Network (DNN) models. Using a combination of **Generative Adversarial Networks (GANs)** and the **Non-dominated Sorting Genetic Algorithm II (NSGA-II)**, DiffGAN generates diverse and valid inputs that highlight the functional differences between DNN models.

The project evaluates the ability of DiffGAN to outperform a state-of-the-art baseline, **DRFuzz**, in terms of:
- Quantity and validity of triggering inputs.
- Diversity of generated inputs.
- Improved model selection through training with generated triggering inputs.

---

## Workflow Diagram
The following diagram outlines the **DiffGAN** workflow, including the GAN-based test generation and fitness evaluation phases:
![image](https://github.com/user-attachments/assets/aefedaf6-fb59-49d6-be64-1945cc42e380)


---

## Repository Structure
```
Diff_testing_GAN/
│
├── DNN_Models/                    # Pre-trained DNN models
├── DRFuzz-main/                   # Code and data of the DRFuzz baseline
├── RQ4/                           # Research Question 4
├── TestGAN_Run/MNIST_S1/time_1h/  # Test runs and triggering images generated by DiffGAN
├── Training/                      # Pre_trained GAN components and data
│
├── PreProcessing_Training.ipynb   # Notebook for preprocessing data and training models
├── RQ2_RQ3_RQ4.ipynb              # Notebooks of Research Questions 2, 3, and 4
└── organized_DiffGAN.ipynb        # Main DiffGAN pipeline and RQ1 experiments 
```

---

## Installation and Requirements

### Python and Libraries

This project has been tested with **Python 3.10.12**. Below are the required libraries and their versions:

| Library          | Version    |
|------------------|------------|
| TensorFlow       | 2.17.0     |
| PyTorch          | 2.4.1+cu121 |
| Torchvision      | 0.19.1+cu121 |
| UMAP             | 0.5.6      |
| pymoo            | 0.6.1.3    |
| Scikit-learn     | 1.5.2      |
| Matplotlib       | 3.7.1      |
| Seaborn          | 0.13.1     |
| NumPy            | 1.26.4     |
| SciPy            | 1.13.1     |
| Pillow           | 10.4.0     |
| TQDM             | 4.66.5     |
| PyTorch FID      | 0.3.0      |

### Installation Commands
To install the required libraries, run the following commands, Note that they are some specific required libraries in each notebook as well:

```bash
# Core dependencies for testing and analysis
pip install NearPy
pip install pymoo
pip install hdbscan
pip install umap-learn

# Machine Learning libraries and frameworks
pip install tensorflow==2.17.0
pip install torch==2.4.1+cu121 torchvision==0.19.1+cu121
pip install scikit-learn==1.5.2
pip install torch-fidelity==0.3.0  # PyTorch FID

# Visualization and plotting
pip install matplotlib==3.7.1
pip install seaborn==0.13.1

# Other required libraries
pip install numpy==1.26.4 scipy==1.13.1
pip install pillow==10.4.0 tqdm==4.66.5
```
---

## Usage
1. **Training the GAN:** Use the notebook `PreProcessing_Training.ipynb` to train the GAN models on your datasets.
2. **Running Experiments:** 
   - The main pipeline for DiffGAN is available in `organized_DiffGAN.ipynb`.
   - Use `RQ2_RQ3_RQ4.ipynb` to rerun the research questions.
3. **Comparison with DRFuzz:** The DRFuzz implementation is provided in the `DRFuzz-main/` folder. Use it to replicate the baseline experiments.

---
## Interesting Result
**Triggering Images Generated by DiffGAN:**
Below are some examples of triggering inputs generated by DiffGAN. These images highlight an interesting behavioral difference between the two DNN models being evaluated:
![image](https://github.com/user-attachments/assets/a8081bf1-b800-41c7-929a-a26b3e5b2f8d)

**Observation:**
DNN Model 2 demonstrates higher overall accuracy compared to Model 1; however, it has been observed that Model 2 tends to be overly sensitive to details. This focus on finer details occasionally leads it to miss the broader context of the input, resulting in misclassification.
For example, as seen in the above images:
Some inputs are correctly classified by Model 1, while Model 2 overlooks them.
Model 2 sometimes emphasizes trivial variations in the image, leading to unexpected behaviors.

**Diversity Comparison**
We compared the diversity of the inputs generated by DFlare, DRFuzz, and our approach (DiffGAN) on the MNIST dataset using four model pairs. Similar to RQ3, we used Geometric Diversity (GD) and Shannon Entropy as metrics to measure input diversity. The configuration for this comparison was fixed to 1 hour.

Our results clearly demonstrate that DiffGAN outperforms significantly than both DRFuzz and DiffGAN across all model pairs

Table: Diversity Scores of MNIST (1h Configuration)

| Models | Method  | GD         | Shannon Entropy         |
| ------ | ------- | ---------- | ----------------------- |
| M1, M2 | DFlare  | -377.52    | 4.7435                  |
|        | DRFuzz  | 422.03     | 11.36 (≈86,361.86)      |
|        | DiffGAN | **530.62** | **12.10 (≈178,632.90)** |
| M3, M4 | DFlare  | 132.15     | 4.7468                  |
|        | DRFuzz  | 438.42     | 11.39 (≈89,882.98)      |
|        | DiffGAN | **727.20** | **12.21 (≈200,195.46)** |
| M5, M6 | DFlare  | -72.37     | 4.7666                  |
|        | DRFuzz  | 410.67     | 11.50 (≈98,610.81)      |
|        | DiffGAN | **712.76** | **12.27 (≈213,402.74)** |
| M7, M8 | DFlare  | 36.42      | 4.7855                  |
|        | DRFuzz  | 116.72     | 11.40 (≈90,159.89)      |
|        | DiffGAN | **481.94** | **12.18 (≈178,751.64)** |





**Ablation study result:**

![image](https://github.com/user-attachments/assets/28540800-42f2-442f-8eea-5ce55780decd)


**Training scalability**

![fig](https://github.com/user-attachments/assets/49d02a93-8f05-4b68-a3f4-090ee66996f4)


### Insights
This finding highlights the importance of generating diverse triggering inputs to reveal subtle discrepancies between models. It suggests that even highly accurate models might not always be the most reliable under specific conditions. This insight can be crucial for model selection mechanisms, where understanding model behavior under edge cases helps optimize the use of multiple DNN models.


## Citation
If you use this code in your research, please cite our paper

## Acknowledgments
This research was supported by a grant from General Motors, as well as the Canada Research Chair and Discovery Grant programs of the Natural Sciences and Engineering Research Council of Canada (NSERC). We also thank the developers of [**DRFuzz**](https://doi.org/10.1109/ICSE43902.2021.00111) for making their code available for comparison.

